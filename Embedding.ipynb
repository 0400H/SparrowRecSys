{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1307bbdf-e411-4828-9d2d-4d28ec06da7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import BucketedRandomProjectionLSH\n",
    "from pyspark.mllib.feature import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "736e9274-5678-46ac-8ea8-3da5dc841117",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UdfFunction:\n",
    "    @staticmethod\n",
    "    def sortF(movie_list, timestamp_list):\n",
    "        \"\"\"\n",
    "        sort by time and return the corresponding movie sequence\n",
    "        eg:\n",
    "            input: movie_list:[1,2,3]\n",
    "                   timestamp_list:[1112486027,1212546032,1012486033]\n",
    "            return [3,1,2]\n",
    "        \"\"\"\n",
    "        pairs = []\n",
    "        for m, t in zip(movie_list, timestamp_list):\n",
    "            pairs.append((m, t))\n",
    "        # sort by time\n",
    "        pairs = sorted(pairs, key=lambda x: x[1])\n",
    "        return [x[0] for x in pairs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e604ec38-0d2b-464c-92ca-7e8de8cc4f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processItemSequence(spark, rawSampleDataPath):\n",
    "    # rating data\n",
    "    ratingSamples = spark.read.format(\"csv\").option(\"header\", \"true\").load(rawSampleDataPath)\n",
    "    # ratingSamples.show(5)\n",
    "    # ratingSamples.printSchema()\n",
    "    sortUdf = udf(UdfFunction.sortF, ArrayType(StringType()))\n",
    "    userSeq = ratingSamples \\\n",
    "        .where(F.col(\"rating\") >= 3.5) \\\n",
    "        .groupBy(\"userId\") \\\n",
    "        .agg(sortUdf(F.collect_list(\"movieId\"), F.collect_list(\"timestamp\")).alias('movieIds')) \\\n",
    "        .withColumn(\"movieIdStr\", array_join(F.col(\"movieIds\"), \" \"))\n",
    "    # userSeq.select(\"userId\", \"movieIdStr\").show(10, truncate = False)\n",
    "    return userSeq.select('movieIdStr').rdd.map(lambda x: x[0].split(' '))\n",
    "\n",
    "\n",
    "def embeddingLSH(spark, movieEmbMap):\n",
    "    movieEmbSeq = []\n",
    "    for key, embedding_list in movieEmbMap.items():\n",
    "        embedding_list = [np.float64(embedding) for embedding in embedding_list]\n",
    "        movieEmbSeq.append((key, Vectors.dense(embedding_list)))\n",
    "    movieEmbDF = spark.createDataFrame(movieEmbSeq).toDF(\"movieId\", \"emb\")\n",
    "    bucketProjectionLSH = BucketedRandomProjectionLSH(inputCol=\"emb\", outputCol=\"bucketId\", bucketLength=0.1,\n",
    "                                                      numHashTables=3)\n",
    "    bucketModel = bucketProjectionLSH.fit(movieEmbDF)\n",
    "    embBucketResult = bucketModel.transform(movieEmbDF)\n",
    "    print(\"movieId, emb, bucketId schema:\")\n",
    "    embBucketResult.printSchema()\n",
    "    print(\"movieId, emb, bucketId data result:\")\n",
    "    embBucketResult.show(10, truncate=False)\n",
    "    print(\"Approximately searching for 5 nearest neighbors of the sample embedding:\")\n",
    "    sampleEmb = Vectors.dense(0.795, 0.583, 1.120, 0.850, 0.174, -0.839, -0.0633, 0.249, 0.673, -0.237)\n",
    "    bucketModel.approxNearestNeighbors(movieEmbDF, sampleEmb, 5).show(truncate=False)\n",
    "\n",
    "\n",
    "def trainItem2vec(spark, samples, embLength, embOutputPath, saveToRedis, redisKeyPrefix):\n",
    "    word2vec = Word2Vec().setVectorSize(embLength).setWindowSize(5).setNumIterations(10)\n",
    "    model = word2vec.fit(samples)\n",
    "    synonyms = model.findSynonyms(\"158\", 20)\n",
    "    for synonym, cosineSimilarity in synonyms:\n",
    "        print(synonym, cosineSimilarity)\n",
    "    embOutputDir = '/'.join(embOutputPath.split('/')[:-1])\n",
    "    if not os.path.exists(embOutputDir):\n",
    "        os.makedirs(embOutputDir)\n",
    "    with open(embOutputPath, 'w') as f:\n",
    "        for movie_id in model.getVectors():\n",
    "            vectors = \" \".join([str(emb) for emb in model.getVectors()[movie_id]])\n",
    "            f.write(movie_id + \":\" + vectors + \"\\n\")\n",
    "    embeddingLSH(spark, model.getVectors())\n",
    "    return model\n",
    "\n",
    "\n",
    "def generate_pair(x):\n",
    "    # eg:\n",
    "    # watch sequence:['858', '50', '593', '457']\n",
    "    # return:[['858', '50'],['50', '593'],['593', '457']]\n",
    "    pairSeq = []\n",
    "    previousItem = ''\n",
    "    for item in x:\n",
    "        if not previousItem:\n",
    "            previousItem = item\n",
    "        else:\n",
    "            pairSeq.append((previousItem, item))\n",
    "            previousItem = item\n",
    "    return pairSeq\n",
    "\n",
    "\n",
    "def generateTransitionMatrix(samples):\n",
    "    pairSamples = samples.flatMap(lambda x: generate_pair(x))\n",
    "    pairCountMap = pairSamples.countByValue()\n",
    "    pairTotalCount = 0\n",
    "    transitionCountMatrix = defaultdict(dict)\n",
    "    itemCountMap = defaultdict(int)\n",
    "    for key, cnt in pairCountMap.items():\n",
    "        key1, key2 = key\n",
    "        transitionCountMatrix[key1][key2] = cnt\n",
    "        itemCountMap[key1] += cnt\n",
    "        pairTotalCount += cnt\n",
    "    transitionMatrix = defaultdict(dict)\n",
    "    itemDistribution = defaultdict(dict)\n",
    "    for key1, transitionMap in transitionCountMatrix.items():\n",
    "        for key2, cnt in transitionMap.items():\n",
    "            transitionMatrix[key1][key2] = transitionCountMatrix[key1][key2] / itemCountMap[key1]\n",
    "    for itemid, cnt in itemCountMap.items():\n",
    "        itemDistribution[itemid] = cnt / pairTotalCount\n",
    "    return transitionMatrix, itemDistribution\n",
    "\n",
    "\n",
    "def oneRandomWalk(transitionMatrix, itemDistribution, sampleLength):\n",
    "    sample = []\n",
    "    # pick the first element\n",
    "    randomDouble = random.random()\n",
    "    firstItem = \"\"\n",
    "    accumulateProb = 0.0\n",
    "    for item, prob in itemDistribution.items():\n",
    "        accumulateProb += prob\n",
    "        if accumulateProb >= randomDouble:\n",
    "            firstItem = item\n",
    "            break\n",
    "    sample.append(firstItem)\n",
    "    curElement = firstItem\n",
    "    i = 1\n",
    "    while i < sampleLength:\n",
    "        if (curElement not in itemDistribution) or (curElement not in transitionMatrix):\n",
    "            break\n",
    "        probDistribution = transitionMatrix[curElement]\n",
    "        randomDouble = random.random()\n",
    "        accumulateProb = 0.0\n",
    "        for item, prob in probDistribution.items():\n",
    "            accumulateProb += prob\n",
    "            if accumulateProb >= randomDouble:\n",
    "                curElement = item\n",
    "                break\n",
    "        sample.append(curElement)\n",
    "        i += 1\n",
    "    return sample\n",
    "\n",
    "\n",
    "def randomWalk(transitionMatrix, itemDistribution, sampleCount, sampleLength):\n",
    "    samples = []\n",
    "    for i in range(sampleCount):\n",
    "        samples.append(oneRandomWalk(transitionMatrix, itemDistribution, sampleLength))\n",
    "    return samples\n",
    "\n",
    "\n",
    "def graphEmb(samples, spark, embLength, embOutputFilename, saveToRedis, redisKeyPrefix):\n",
    "    transitionMatrix, itemDistribution = generateTransitionMatrix(samples)\n",
    "    sampleCount = 20000\n",
    "    sampleLength = 10\n",
    "    newSamples = randomWalk(transitionMatrix, itemDistribution, sampleCount, sampleLength)\n",
    "    rddSamples = spark.sparkContext.parallelize(newSamples)\n",
    "    trainItem2vec(spark, rddSamples, embLength, embOutputFilename, saveToRedis, redisKeyPrefix)\n",
    "\n",
    "\n",
    "def generateUserEmb(spark, rawSampleDataPath, model, embLength, embOutputPath, saveToRedis, redisKeyPrefix):\n",
    "    ratingSamples = spark.read.format(\"csv\").option(\"header\", \"true\").load(rawSampleDataPath)\n",
    "    Vectors_list = []\n",
    "    for key, value in model.getVectors().items():\n",
    "        Vectors_list.append((key, list(value)))\n",
    "    fields = [\n",
    "        StructField('movieId', StringType(), False),\n",
    "        StructField('emb', ArrayType(FloatType()), False)\n",
    "    ]\n",
    "    schema = StructType(fields)\n",
    "    Vectors_df = spark.createDataFrame(Vectors_list, schema=schema)\n",
    "    ratingSamples = ratingSamples.join(Vectors_df, on='movieId', how='inner')\n",
    "    result = ratingSamples.select('userId', 'emb').rdd.map(lambda x: (x[0], x[1])) \\\n",
    "        .reduceByKey(lambda a, b: [a[i] + b[i] for i in range(len(a))]).collect()\n",
    "    with open(embOutputPath, 'w') as f:\n",
    "        for row in result:\n",
    "            vectors = \" \".join([str(emb) for emb in row[1]])\n",
    "            f.write(row[0] + \":\" + vectors + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2385b340-7ffa-4cba-ad38-0db172964561",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/09/27 06:00:04 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/09/27 06:00:23 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48 0.9576151967048645\n",
      "256 0.9569064378738403\n",
      "31 0.9292811155319214\n",
      "186 0.8966360688209534\n",
      "277 0.8789969682693481\n",
      "355 0.8673171401023865\n",
      "276 0.8661347031593323\n",
      "552 0.8645269870758057\n",
      "252 0.8509904146194458\n",
      "520 0.8378013968467712\n",
      "168 0.8356328010559082\n",
      "333 0.803519606590271\n",
      "44 0.7937459945678711\n",
      "237 0.7861098051071167\n",
      "455 0.7774463891983032\n",
      "236 0.7672165036201477\n",
      "368 0.7663686275482178\n",
      "169 0.7624613046646118\n",
      "370 0.7593098878860474\n",
      "432 0.756442129611969\n",
      "movieId, emb, bucketId schema:\n",
      "root\n",
      " |-- movieId: string (nullable = true)\n",
      " |-- emb: vector (nullable = true)\n",
      " |-- bucketId: array (nullable = true)\n",
      " |    |-- element: vector (containsNull = true)\n",
      "\n",
      "movieId, emb, bucketId data result:\n",
      "+-------+-----------------------------------------------------------------------------------------------------------------------+-----------------------+\n",
      "|movieId|emb                                                                                                                    |bucketId               |\n",
      "+-------+-----------------------------------------------------------------------------------------------------------------------+-----------------------+\n",
      "|710    |[-0.07219975,0.91513556,0.6346075,-1.0431635,1.4083766,-0.873591,-0.20458587,-0.16557342,1.541165,0.6380867]           |[[6.0], [8.0], [12.0]] |\n",
      "|205    |[-0.2990372,0.09977074,0.4559034,-0.34253624,0.97394717,0.54570365,0.14508106,0.013157304,0.32846665,0.08591336]       |[[-5.0], [8.0], [1.0]] |\n",
      "|45     |[-0.32623747,-0.14238964,0.1736604,-0.11488594,0.23057175,0.97218436,-0.0017732475,0.09965057,0.42910773,-0.28245473]  |[[-5.0], [1.0], [-1.0]]|\n",
      "|515    |[-0.46439853,-0.4322345,0.41788653,0.2066108,0.15611582,0.8626379,0.18650793,-0.3022875,0.15480185,-0.6029075]         |[[-7.0], [1.0], [-6.0]]|\n",
      "|574    |[-0.17809257,-0.089483894,0.018346544,-0.508763,0.72358954,0.7010817,0.41480997,0.08691219,0.6365752,-0.025789963]     |[[-5.0], [4.0], [3.0]] |\n",
      "|858    |[-0.12555653,-0.04321471,-0.57767344,-0.14078785,0.07011372,-0.46267626,0.0021235633,-0.4311451,0.12757203,-0.30167833]|[[3.0], [-2.0], [0.0]] |\n",
      "|619    |[-0.12350747,0.6376919,0.45722064,-0.68693334,1.0208776,-0.4558688,-0.095132336,-0.21766987,1.0076723,0.42252028]      |[[3.0], [6.0], [7.0]]  |\n",
      "|507    |[0.4434076,-0.3287662,0.26619217,-0.24030814,0.2738088,0.34964204,-0.17951468,0.08304907,0.10226328,-0.04715175]       |[[-6.0], [2.0], [-2.0]]|\n",
      "|113    |[0.1474006,0.5567863,0.86567956,-0.3679177,1.3923273,-0.5028616,0.17453124,-0.55371034,0.79226375,0.14200185]          |[[-2.0], [10.0], [1.0]]|\n",
      "|34     |[-0.3159283,-0.029194271,-0.32437667,0.10016197,0.60641813,-0.051144026,0.44045785,0.4397103,-0.29291052,-0.10842324]  |[[-4.0], [4.0], [0.0]] |\n",
      "+-------+-----------------------------------------------------------------------------------------------------------------------+-----------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Approximately searching for 5 nearest neighbors of the sample embedding:\n",
      "+-------+------------------------------------------------------------------------------------------------------------------+------------------------+------------------+\n",
      "|movieId|emb                                                                                                               |bucketId                |distCol           |\n",
      "+-------+------------------------------------------------------------------------------------------------------------------+------------------------+------------------+\n",
      "|168    |[0.3959272,0.067853905,0.8982209,0.45134813,-0.0779236,-0.0024525814,-0.5823293,0.49479234,0.4134158,-0.6843231]  |[[-7.0], [-3.0], [-6.0]]|1.411845659657101 |\n",
      "|186    |[-0.04497551,0.31442952,0.9292185,0.577359,-0.1616661,-0.19882049,-0.24159472,0.7209916,0.5369569,-0.79714257]    |[[-5.0], [-5.0], [-3.0]]|1.4134191497562725|\n",
      "|252    |[-0.21812582,0.33251306,0.8164877,0.5853502,0.06762813,-0.009745676,-0.055538144,0.6077912,0.41724902,-0.5955535] |[[-5.0], [-2.0], [-3.0]]|1.5076687711469567|\n",
      "|236    |[-0.37072024,0.25181216,0.84656245,0.5412033,0.0372864,-0.23086195,0.13869865,0.6272938,0.3601533,-0.7174949]     |[[-5.0], [-2.0], [-2.0]]|1.5937042120859004|\n",
      "|119    |[0.26712894,-0.26594928,0.56806034,-0.01511123,0.5414489,-0.40476206,-0.05854076,0.37594587,0.77050436,0.42415583]|[[-5.0], [-1.0], [0.0]] |1.684865241862137 |\n",
      "+-------+------------------------------------------------------------------------------------------------------------------+------------------------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/09/27 06:02:29 WARN TaskSetManager: Stage 50 contains a task of very large size (1145 KiB). The maximum recommended task size is 1000 KiB.\n",
      "23/09/27 06:02:30 WARN TaskSetManager: Stage 52 contains a task of very large size (1145 KiB). The maximum recommended task size is 1000 KiB.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256 0.9598774909973145\n",
      "48 0.9271106719970703\n",
      "204 0.8940199017524719\n",
      "186 0.8814314603805542\n",
      "168 0.8698970675468445\n",
      "252 0.8410778045654297\n",
      "31 0.822386622428894\n",
      "261 0.8179829120635986\n",
      "44 0.8030238747596741\n",
      "553 0.7992665767669678\n",
      "277 0.7878677845001221\n",
      "355 0.7848019599914551\n",
      "172 0.7834339737892151\n",
      "350 0.7736256718635559\n",
      "315 0.7720025181770325\n",
      "151 0.7537885904312134\n",
      "594 0.7494053840637207\n",
      "368 0.7447748780250549\n",
      "193 0.7361211180686951\n",
      "196 0.7348687648773193\n",
      "movieId, emb, bucketId schema:\n",
      "root\n",
      " |-- movieId: string (nullable = true)\n",
      " |-- emb: vector (nullable = true)\n",
      " |-- bucketId: array (nullable = true)\n",
      " |    |-- element: vector (containsNull = true)\n",
      "\n",
      "movieId, emb, bucketId data result:\n",
      "+-------+----------------------------------------------------------------------------------------------------------------------+------------------------+\n",
      "|movieId|emb                                                                                                                   |bucketId                |\n",
      "+-------+----------------------------------------------------------------------------------------------------------------------+------------------------+\n",
      "|710    |[-0.013728228,-0.3276701,1.2022406,0.28557295,1.0825553,-0.31669486,-0.57661575,0.08040349,0.28301936,-0.6218461]     |[[-11.0], [6.0], [-8.0]]|\n",
      "|205    |[0.02099821,-0.2416558,0.5864659,0.09558404,0.33997732,-0.47512037,-0.5276754,-0.38654464,-0.021615125,0.16671772]    |[[-2.0], [2.0], [-4.0]] |\n",
      "|45     |[0.23128918,-0.046539824,-0.17792417,0.07527744,0.21565631,-0.09480874,-0.100422114,-0.49701548,0.276481,0.37711126]  |[[0.0], [0.0], [-2.0]]  |\n",
      "|515    |[-0.09374382,-0.24112342,0.047425486,0.018580765,0.07975594,-0.20356041,0.2920841,-0.61812514,0.32544214,0.6560631]   |[[1.0], [-2.0], [0.0]]  |\n",
      "|574    |[-0.22413675,0.23481533,0.07799538,0.38186812,0.81654376,0.20856626,-0.21731327,-0.33286864,0.42465118,0.37997806]    |[[-2.0], [4.0], [-3.0]] |\n",
      "|858    |[0.012993944,0.35419092,-0.22263682,0.0019630222,0.51432973,0.04812307,0.36484438,0.101089805,-0.21098478,-0.21891719]|[[-2.0], [5.0], [0.0]]  |\n",
      "|619    |[0.04701058,-0.50161767,0.7159262,0.15825574,0.23622653,0.14835759,-0.2683787,-0.23729788,0.12676749,-0.25663406]     |[[-7.0], [0.0], [-6.0]] |\n",
      "|507    |[-0.10731255,0.4522517,0.20924275,0.059885226,-0.012873342,0.167497,-0.108377,-0.6921618,0.29733053,0.31397307]       |[[4.0], [1.0], [0.0]]   |\n",
      "|113    |[-0.6581446,0.0135640325,1.3858683,-0.102675185,0.75803083,0.9647321,-0.9271037,-0.24557854,0.21691209,0.056530487]   |[[-6.0], [9.0], [-3.0]] |\n",
      "|34     |[0.08598897,0.3362959,0.043047693,0.1655299,0.16036734,-0.672059,-0.012052617,-0.026261263,-0.3374964,0.10301795]     |[[2.0], [2.0], [-1.0]]  |\n",
      "+-------+----------------------------------------------------------------------------------------------------------------------+------------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Approximately searching for 5 nearest neighbors of the sample embedding:\n",
      "+-------+-----------------------------------------------------------------------------------------------------------------------+------------------------+------------------+\n",
      "|movieId|emb                                                                                                                    |bucketId                |distCol           |\n",
      "+-------+-----------------------------------------------------------------------------------------------------------------------+------------------------+------------------+\n",
      "|410    |[0.333135,0.30938816,-0.06157075,0.048501924,-0.027628427,-0.50212353,-0.29796836,0.0962654,0.34561294,-0.10577142]    |[[2.0], [-3.0], [0.0]]  |1.6381793013590165|\n",
      "|567    |[0.41316918,-0.005117292,0.18748467,0.17189802,-0.1010958,-0.42001733,-0.0291012,-0.35959047,0.22965968,0.05357814]    |[[0.0], [-3.0], [-3.0]] |1.6507108317431032|\n",
      "|700    |[0.08433858,-0.13606253,0.3694467,0.0031098635,-0.020367296,-0.64261097,-0.47478154,-0.28158766,0.40909776,-0.05524236]|[[1.0], [-3.0], [-1.0]] |1.7124577620798194|\n",
      "|242    |[-0.19840237,-0.55636775,0.90619344,0.5962271,0.16843998,-0.58992064,-0.25986943,-0.3552698,0.36275187,-0.046029724]   |[[-5.0], [-3.0], [-7.0]]|1.7302305020493978|\n",
      "|225    |[0.08552285,0.38276827,-0.15370351,-0.034691993,-0.020141928,-0.7074152,-0.30763224,0.21972838,0.42725223,-0.029950038]|[[4.0], [-3.0], [3.0]]  |1.779683538778499 |\n",
      "+-------+-----------------------------------------------------------------------------------------------------------------------+------------------------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    url = \"\"\n",
    "    conf = SparkConf().setAppName('ctrModel').setMaster('local')\n",
    "    spark = SparkSession.builder.config(conf=conf).getOrCreate()\n",
    "    # Change to your own filepath\n",
    "    file_path = 'file:///mnt/home/0400h/github/SparrowRecSys/'\n",
    "    rawSampleDataPath = file_path + \"sampledata/ratings.csv\"\n",
    "    embLength = 10\n",
    "    samples = processItemSequence(spark, rawSampleDataPath)\n",
    "    model = trainItem2vec(spark, samples, embLength,\n",
    "                          embOutputPath=file_path[7:] + \"modeldata/item2vecEmb.csv\", saveToRedis=False,\n",
    "                          redisKeyPrefix=\"i2vEmb\")\n",
    "    graphEmb(samples, spark, embLength, embOutputFilename=file_path[7:] + \"modeldata/itemGraphEmb.csv\",\n",
    "             saveToRedis=True, redisKeyPrefix=\"graphEmb\")\n",
    "    generateUserEmb(spark, rawSampleDataPath, model, embLength,\n",
    "                    embOutputPath=file_path[7:] + \"modeldata/userEmb.csv\", saveToRedis=False,\n",
    "                    redisKeyPrefix=\"uEmb\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b77e582-8e22-4d27-bf2e-3fc5e23f6a77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
